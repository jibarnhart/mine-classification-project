{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ccf7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149c22a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame datatypes :\n",
      " 0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "       ...   \n",
      "56    float64\n",
      "57    float64\n",
      "58    float64\n",
      "59    float64\n",
      "60     object\n",
      "Length: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sonar = pd.read_csv(\"data/sonar.csv\",header=None, na_values='?').dropna()\n",
    "sonar.head()\n",
    "print('\\nDataFrame datatypes :\\n', sonar.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1700230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681c7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xson = sonar.drop([60], axis=1) # X variable is the dataset without the class column\n",
    "Xson = Xson.values \n",
    "Yson = sonar.iloc[:,60].values\n",
    "Yson_int = np.empty((208))\n",
    "for i in range(np.shape(Yson)[0]):\n",
    "    if Yson[i] == 'R':\n",
    "        Yson_int[i] = 0\n",
    "    if Yson[i] == 'M':\n",
    "        Yson_int[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f6f01",
   "metadata": {},
   "source": [
    "Standardizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e635921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_son = np.reshape(Xson.mean(0), (-1,60))\n",
    "X_std_son = np.reshape(Xson.std(0), (-1,60))\n",
    "X_stand_son = (Xson - X_mean_son) / X_std_son  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c2126",
   "metadata": {},
   "source": [
    "Separate into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90cf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as cv\n",
    "XTrain_son, XTest_son, YTrain_son, YTest_son = cv.train_test_split(X_stand_son, Yson_int,\n",
    "    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "539205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca515a0",
   "metadata": {},
   "source": [
    "We can do a small grid search to find the best solving method for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf8b19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "\n",
    "cv_lda = GridSearchCV(estimator=lda, param_grid=grid, scoring='accuracy', cv=ms.KFold(n_splits=10), n_jobs=-1)\n",
    "results_lda = cv_lda.fit(XTrain_son, YTrain_son)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24147c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
      "             estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
      "             param_grid={'solver': ['svd', 'lsqr', 'eigen']},\n",
      "             scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(results_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6cd0d",
   "metadata": {},
   "source": [
    "SVD is the best solving method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432ad0f",
   "metadata": {},
   "source": [
    "Now we can tune the number of neighbors in the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13f1c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=13, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "neighbor= np.arange(1,16)\n",
    "param_grid=dict(n_neighbors=neighbor)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "grid_search=GridSearchCV(knn, param_grid=param_grid, cv=ms.KFold(n_splits=13), scoring='accuracy')\n",
    "grid_search.fit(XTrain_son, YTrain_son) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaed09d",
   "metadata": {},
   "source": [
    "The best number of neighbors is 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87810a9",
   "metadata": {},
   "source": [
    "Now we have some functions I made to return some key performance metrics for each of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a74818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(Y_true, Y_pred):\n",
    "    n = np.shape(Y_true)[0]\n",
    "    class metric:\n",
    "        matrix = np.empty((2,2))\n",
    "        recall = float()\n",
    "        specificity = float()\n",
    "        fallout = float()\n",
    "        ppv = float()\n",
    "        accuracy = float()\n",
    "        missclassification = float()\n",
    "    metrics = metric()\n",
    "    tp = tn = fp = fn = 0\n",
    "    for i in range(n):\n",
    "        if Y_true[i] == Y_pred[i]:\n",
    "            if Y_true[i] == 1:\n",
    "                tp += 1\n",
    "            if Y_true[i] == 0:\n",
    "                tn += 1\n",
    "        if Y_true[i] != Y_pred[i]:\n",
    "            if Y_true[i] == 1:\n",
    "                fn += 1\n",
    "            if Y_true[i] == 0:\n",
    "                fp += 1\n",
    "    confusion = np.array([[tp, fn], [fp, tn]])\n",
    "    metrics.matrix = confusion\n",
    "    metrics.recall = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "    metrics.specificity = confusion[1,1]/(confusion[1,1]+confusion[1,0])\n",
    "    metrics.fallout = confusion[1,0]/(confusion[1,0]+confusion[1,1])\n",
    "    metrics.ppv = confusion[0,0]/(confusion[0,0]+confusion[1,0])\n",
    "    metrics.accuracy = (confusion[0,0]+confusion[1,1])/np.sum(confusion)\n",
    "    metrics.missclassification = (confusion[0,1]+confusion[1,0])/np.sum(confusion)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print('The confusion matrix is        ', metrics.matrix[0,:])\n",
    "    print('                               ', metrics.matrix[1,:])\n",
    "    print('\\n')\n",
    "    print('The metrics are:        Fallout =', round(metrics.fallout,4),'               Recall =', round(metrics.recall,4))\n",
    "    print('                    Specificity =', round(metrics.specificity,4), '                  PPV =', round(metrics.ppv,4))\n",
    "    print('                       Accuracy =', round(metrics.accuracy,4), ' Missclass Error Rate =', round(metrics.missclassification,4))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba01d2bd",
   "metadata": {},
   "source": [
    "First the LDA metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42491e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Training Metrics:\n",
      "The confusion matrix is         [84  7]\n",
      "                                [ 8 67]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.1067                Recall = 0.9231\n",
      "                    Specificity = 0.8933                   PPV = 0.913\n",
      "                       Accuracy = 0.9096  Missclass Error Rate = 0.0904\n",
      "\n",
      "\n",
      "LDA Testing Metrics:\n",
      "The confusion matrix is         [15  5]\n",
      "                                [ 8 14]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.3636                Recall = 0.75\n",
      "                    Specificity = 0.6364                   PPV = 0.6522\n",
      "                       Accuracy = 0.6905  Missclass Error Rate = 0.3095\n"
     ]
    }
   ],
   "source": [
    "lda=LinearDiscriminantAnalysis(solver='svd') # solver found from GridSearchCV\n",
    "lda.fit(XTrain_son, YTrain_son)\n",
    "lda_pred_train=lda.predict(XTrain_son)\n",
    "lda_pred_test=lda.predict(XTest_son)\n",
    "lda_train_metrics = classification_metrics(YTrain_son, lda_pred_train)\n",
    "lda_test_metrics = classification_metrics(YTest_son, lda_pred_test)\n",
    "print('LDA Training Metrics:')\n",
    "print_metrics(lda_train_metrics)\n",
    "print('\\n')\n",
    "print('LDA Testing Metrics:')\n",
    "print_metrics(lda_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b4927",
   "metadata": {},
   "source": [
    "now the QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db0f1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Training Metrics:\n",
      "The confusion matrix is         [91  0]\n",
      "                                [ 0 75]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.0                Recall = 1.0\n",
      "                    Specificity = 1.0                   PPV = 1.0\n",
      "                       Accuracy = 1.0  Missclass Error Rate = 0.0\n",
      "\n",
      "\n",
      "QDA Testing Metrics:\n",
      "The confusion matrix is         [20  0]\n",
      "                                [12 10]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.5455                Recall = 1.0\n",
      "                    Specificity = 0.4545                   PPV = 0.625\n",
      "                       Accuracy = 0.7143  Missclass Error Rate = 0.2857\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(XTrain_son, YTrain_son)\n",
    "qda_pred_train=qda.predict(XTrain_son)\n",
    "qda_pred_test=qda.predict(XTest_son)\n",
    "qda_train_metrics = classification_metrics(YTrain_son, qda_pred_train)\n",
    "qda_test_metrics = classification_metrics(YTest_son, qda_pred_test)\n",
    "print('QDA Training Metrics:')\n",
    "print_metrics(qda_train_metrics)\n",
    "print('\\n')\n",
    "print('QDA Testing Metrics:')\n",
    "print_metrics(qda_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176f1f0",
   "metadata": {},
   "source": [
    "We can make our logistic model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee76314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(XTrain_son, YTrain_son)\n",
    "logit_pred_train = logit.predict(XTrain_son)\n",
    "logit_pred_test = logit.predict(XTest_son)\n",
    "logit_train_metrics = classification_metrics(YTrain_son, logit_pred_train)\n",
    "logit_test_metrics = classification_metrics(YTest_son, logit_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ff56358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Training Metrics:\n",
      "The confusion matrix is         [86  5]\n",
      "                                [ 4 71]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.0533                Recall = 0.9451\n",
      "                    Specificity = 0.9467                   PPV = 0.9556\n",
      "                       Accuracy = 0.9458  Missclass Error Rate = 0.0542\n",
      "\n",
      "\n",
      "Logit Testing Metrics:\n",
      "The confusion matrix is         [15  5]\n",
      "                                [ 7 15]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.3182                Recall = 0.75\n",
      "                    Specificity = 0.6818                   PPV = 0.6818\n",
      "                       Accuracy = 0.7143  Missclass Error Rate = 0.2857\n"
     ]
    }
   ],
   "source": [
    "print('Logit Training Metrics:')\n",
    "print_metrics(logit_train_metrics)\n",
    "print('\\n')\n",
    "print('Logit Testing Metrics:')\n",
    "print_metrics(logit_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8182d8d",
   "metadata": {},
   "source": [
    "And lastly we make our KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c973798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4)# Found from GridSearchCV\n",
    "knn.fit(XTrain_son, YTrain_son)\n",
    "knn_pred_train = knn.predict(XTrain_son)\n",
    "knn_pred_test = knn.predict(XTest_son)\n",
    "knn_train_metrics = classification_metrics(YTrain_son, knn_pred_train)\n",
    "knn_test_metrics = classification_metrics(YTest_son, knn_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "064f85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Metrics:\n",
      "The confusion matrix is         [81 10]\n",
      "                                [ 5 70]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.0667                Recall = 0.8901\n",
      "                    Specificity = 0.9333                   PPV = 0.9419\n",
      "                       Accuracy = 0.9096  Missclass Error Rate = 0.0904\n",
      "\n",
      "\n",
      "KNN Testing Metrics:\n",
      "The confusion matrix is         [17  3]\n",
      "                                [ 5 17]\n",
      "\n",
      "\n",
      "The metrics are:        Fallout = 0.2273                Recall = 0.85\n",
      "                    Specificity = 0.7727                   PPV = 0.7727\n",
      "                       Accuracy = 0.8095  Missclass Error Rate = 0.1905\n"
     ]
    }
   ],
   "source": [
    "print('KNN Training Metrics:')\n",
    "print_metrics(knn_train_metrics)\n",
    "print('\\n')\n",
    "print('KNN Testing Metrics:')\n",
    "print_metrics(knn_test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5d58baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA missclassification error rate for training is 0.0904  and for testing is 0.3095\n",
      "QDA missclassification error rate for training is 0.0  and for testing is 0.2857\n",
      "Logit missclassification error rate for training is 0.0542  and for testing is 0.2857\n",
      "KNN missclassification error rate for training is 0.0904  and for testing is 0.1905\n"
     ]
    }
   ],
   "source": [
    "print('LDA missclassification error rate for training is'\\\n",
    "      , round(lda_train_metrics.missclassification,4), ' and for testing is'\\\n",
    "      , round(lda_test_metrics.missclassification,4))\n",
    "print('QDA missclassification error rate for training is'\\\n",
    "      , round(qda_train_metrics.missclassification,4), ' and for testing is'\\\n",
    "      , round(qda_test_metrics.missclassification,4))\n",
    "print('Logit missclassification error rate for training is'\\\n",
    "      , round(logit_train_metrics.missclassification,4), ' and for testing is'\\\n",
    "      , round(logit_test_metrics.missclassification,4))\n",
    "print('KNN missclassification error rate for training is'\\\n",
    "      , round(knn_train_metrics.missclassification,4), ' and for testing is'\\\n",
    "      , round(knn_test_metrics.missclassification,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f778e469",
   "metadata": {},
   "source": [
    "We can see that QDA and Logit models both have the same testing misclassification error rates, and very similar training error rates. To decide on which of these two models to use, we need to break up the misclassification error rates into specific types of misclassification. For the scenario that this dataset is from, a false positive is not detrimental as you are classifying a rock as a mine and which leads to more caution that actually required. The false negatives, however, are much more dangerous as in that situation you would be classifying a dangerous mine as a rock, which could be disastrous. So let us look at the rate of false negatives in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d1835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA False Negative Rate is 0.0\n",
      "Logit False Negative Rate is 0.25\n"
     ]
    }
   ],
   "source": [
    "qda_false_neg = qda_test_metrics.matrix[0,1]/(qda_test_metrics.matrix[0,1] + qda_test_metrics.matrix[0,0])\n",
    "logit_false_neg = logit_test_metrics.matrix[0,1]/(logit_test_metrics.matrix[0,1] + logit_test_metrics.matrix[0,0])\n",
    "print('QDA False Negative Rate is', round(qda_false_neg,4))\n",
    "print('Logit False Negative Rate is', round(logit_false_neg,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4fddb",
   "metadata": {},
   "source": [
    "The QDA classifier has a much lower false negative rate than the logit function. So we can conclude that the QDA classifier is the best for this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
